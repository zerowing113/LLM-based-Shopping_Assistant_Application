from langchain.agents import AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from langchain import hub
from langchain.chains import LLMChain
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import (
    ConversationSummaryBufferMemory,
    ConversationBufferWindowMemory,
)
from model import langchain_llm, llamaindex_embed_model, llamaindex_llm
from langchain_core.prompts import PromptTemplate
from retrieval import Retrieval
import streamlit as st
from streamlit_chat import message

# Construct the JSON agent
from prompt import classify_prompt, react_prompt,PROMPT_TEMPLATE

classify_prompt = PromptTemplate.from_template(classify_prompt)
react_prompt_template = PromptTemplate.from_template(react_prompt)
chain = LLMChain(llm=langchain_llm, prompt=classify_prompt)

def tool_get_RAG():
    """Returns the RAG"""
    from llama_index.core.tools import QueryEngineTool

    retrieval = Retrieval()
    index = retrieval.load_index(llamaindex_embed_model)
    query_engine = retrieval.create_query_engine(index, llamaindex_llm)
    tool = QueryEngineTool.from_defaults(
        query_engine,
        name="VectorDB",
        description="ÄÃ¢y lÃ  cÃ´ng cá»¥ tÃ¬m kiáº¿m sáº£n pháº©m cá»§a cá»­a hÃ ng cellphones",
    )
    # run tool as langchain structured tool
    lc_tool = tool.as_langchain_tool()
    return lc_tool

def get_prompt_input(user_input: str):
    # Construct the JSON agent
    #chain = LLMChain(llm=langchain_llm, prompt=classify_prompt)
    return chain.invoke(
        {
            "question": f"{user_input   }",
            "context": """a. Äá» xuáº¥t sáº£n pháº©m: Sá»­ dá»¥ng lá»i nháº¯c nÃ y khi má»¥c Ä‘Ã­ch cá»§a ngÆ°á»i dÃ¹ng lÃ  khÃ¡m phÃ¡ cÃ¡c sáº£n pháº©m má»›i hoáº·c tÃ¬m Ä‘á» xuáº¥t dá»±a trÃªn sá»Ÿ thÃ­ch hoáº·c giao dá»‹ch mua trÆ°á»›c Ä‘Ã¢y cá»§a há».
         b. Truy xuáº¥t thÃ´ng tin sáº£n pháº©m: Sá»­ dá»¥ng lá»i nháº¯c nÃ y khi ngÆ°á»i dÃ¹ng tÃ¬m kiáº¿m thÃ´ng tin chi tiáº¿t vá» má»™t sáº£n pháº©m cá»¥ thá»ƒ, cháº³ng háº¡n nhÆ° tÃ­nh nÄƒng, thÃ´ng sá»‘ ká»¹ thuáº­t hoáº·c Ä‘Ã¡nh giÃ¡.
         c. CÃ¢u há»i thÆ°á»ng gáº·p Tráº£ lá»i: Sá»­ dá»¥ng lá»i nháº¯c nÃ y khi truy váº¥n cá»§a ngÆ°á»i dÃ¹ng phÃ¹ há»£p vá»›i cÃ¡c cÃ¢u há»i thÆ°á»ng gáº·p hoáº·c giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» há»— trá»£ ká»¹ thuáº­t, chÃ­nh sÃ¡ch cá»§a cÃ¡c sáº£n pháº©m.
         d. Thanh toÃ¡n: Táº­n dá»¥ng lá»i nháº¯c nÃ y Ä‘á»ƒ táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho quÃ¡ trÃ¬nh mua hÃ ng, bao gá»“m xá»­ lÃ½ thÃ´ng tin thanh toÃ¡n, xÃ¡c nháº­n Ä‘Æ¡n hÃ ng vÃ  chi tiáº¿t giao hÃ ng.
         e. KhÃ¡c: Sá»­ dá»¥ng lá»i nháº¯c nÃ y cho cÃ¡c truy váº¥n khÃ´ng phÃ¹ há»£p vá»›i cÃ¡c danh má»¥c trÆ°á»›c Ä‘Ã³, cháº³ng háº¡n nhÆ° cung cáº¥p há»— trá»£ chung, cung cáº¥p há»— trá»£ quáº£n lÃ½ tÃ i khoáº£n hoáº·c xá»­ lÃ½ pháº£n há»“i.""",
        }
    )

def handle_user_prompt(user_prompt):
    user_prompt = user_prompt.splitlines()
    return [
        line.split(": ", maxsplit=1)[1]
        for line in user_prompt
        if line.strip().startswith("Answer:") or line.strip().startswith("Explain:")
    ]

def handle_conversation_turn(user_input: str):
    while True:
        user_prompt_analyzed = get_prompt_input(user_input)
        print("user_prompt_analyzed",user_prompt_analyzed)
        return_prompt = handle_user_prompt(user_prompt_analyzed["text"])
        if return_prompt is not None:
            try:
                if (
                    "Äá» xuáº¥t sáº£n pháº©m" in return_prompt[0]
                    or "Truy xuáº¥t thÃ´ng tin sáº£n pháº©m" in return_prompt[0]
                    or "CÃ¢u há»i thÆ°á»ng gáº·p Tráº£ lá»i" in return_prompt[0]
                    or "Thanh toÃ¡n" in return_prompt[0]
                    or "KhÃ¡c" in return_prompt[0]
                ):
                    if len(return_prompt) > 1:
                        return return_prompt[-1]
                    return return_prompt[0]
            except:
                print("Error, cannot classify user input")

tools = [tool_get_RAG()]

def generate_agent(input):
    user_prompt = handle_conversation_turn(input)
    print(user_prompt)
    react_prompt = PromptTemplate.from_template(
        """
                Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.

        Assistant is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.

        Overall, Assistant is a powerful tool that can {user_prompt}. 


        TOOLS:
        ------

        Assistant has access to the following tools:

        {tools}

        To use a tool, please use the following format:

        ```
        Thought: Do I need to use a tool? Yes
        Action: the action to take, should be one of [{tool_names}]
        Action Input: the input to the action
        Observation: the result of the action
        ... (this Thought/Action/Action Input/Observation can repeat TWICE!!!)
        ```

        When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:

        ```
        Thought: Do I need to use a tool? No
        Final Answer: [your response here]
        ```
        -Please ensure that the answers are as emotionally rich and detailed as possible. 
        - Final Answer should respond in TRADITIONAL VIETNAMESE but Chain of thought steps and action steps are in English
        - If there is a Final Answer, return the result
        - Please try to use a three part structure to output the answer, and try to segment it according to the key points. The answer should be no less than 300 words!!!
        Let's begin!

        New input: {input}
        {agent_scratchpad}
        """,
        partial_variables={"user_prompt": user_prompt},
    )
    # react_prompt.format(user_prompt=user_prompt)

    # Construct the ReAct agent

    # Previous conversation history:
    #     {chat_history}
    agent = create_react_agent(langchain_llm, tools, react_prompt)

    # Create an agent executor by passing in the agent and tools
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        # memory=ConversationBufferWindowMemory(
        #     k=5, memory_key="chat_history", return_messages=True
        # ),
        handle_parsing_errors=True,
    )
    return agent_executor

def handle_react_chat(agent, input):
    # print(agent.memory.load_memory_variables({}))
    return agent.invoke({"input": input})

# if __name__ == "__main__":
#     agent = generate_agent("Giá»›i thiá»‡u cho tÃ´i nhá»¯ng máº«u Ä‘iá»‡n thoáº¡i dÆ°á»›i 700k Ä‘Ã¡ng xem")
#     print(handle_react_chat(agent, "Giá»›i thiá»‡u cho tÃ´i nhá»¯ng máº«u Ä‘iá»‡n thoáº¡i dÆ°á»›i 700k Ä‘Ã¡ng xem"))


# Handle new user input
agent = generate_agent("Giá»›i thiá»‡u cho tÃ´i nhá»¯ng máº«u Ä‘iá»‡n thoáº¡i dÆ°á»›i 700k Ä‘Ã¡ng xem")

# Setting page title and header
st.set_page_config(page_title="SOPE", page_icon=":robot_face:")
st.markdown("<h1 style='text-align: center;'>SOPE - Your smart Shopping Assistant ðŸ˜¬</h1>", unsafe_allow_html=True)

# Initialise session state variables
if 'generated' not in st.session_state:
    st.session_state['generated'] = []
if 'past' not in st.session_state:
    st.session_state['past'] = []
if 'messages' not in st.session_state:
    st.session_state['messages'] = [
        {"role": "system", "content": "You are a helpful assistant."}
    ]

# Sidebar - let user choose model, show total cost of current conversation, and let user clear the current conversation
st.sidebar.title("Sidebar")
counter_placeholder = st.sidebar.empty()
clear_button = st.sidebar.button("Clear Conversation", key="clear")

# reset everything
if clear_button:
    st.session_state['generated'] = []
    st.session_state['past'] = []
    st.session_state['messages'] = [
        {"role": "system", "content": "You are a helpful assistant."}
    ]

# container for chat history
response_container = st.container()
# container for text box
container = st.container()

with container:
    with st.form(key='my_form', clear_on_submit=True):
        user_input = st.text_area("You:", key='input', height=100)
        submit_button = st.form_submit_button(label='Send')

    if submit_button and user_input:
        print("user_input",user_input)
        output = handle_react_chat(agent,user_input)
        print("output",output)
        st.session_state['past'].append(user_input)
        st.session_state['generated'].append(output["output"])

if st.session_state['generated']:
    with response_container:
        for i in range(len(st.session_state['generated'])):
            message(st.session_state["past"][i], is_user=True, key=str(i) + '_user')
            message(st.session_state["generated"][i], key=str(i))